{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import tensorflow as tf \n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the excel data \n",
    "\n",
    "xls_dir = './Traffic_Data'\n",
    "\n",
    "mergedData = pd.DataFrame()\n",
    "traffic_data = []\n",
    "\n",
    "# list all the xls files path to read data from \n",
    "xls_files =  [os.path.join(xls_dir, i) for i in os.listdir(xls_dir) if i[-5:] == \".xlsx\"]\n",
    "\n",
    "\n",
    "# read data from excel \n",
    "for xls in xls_files:\n",
    "    df = pd.read_excel(xls)\n",
    "    traffic_data.append(np.array([df[\"5 Minutes\"],df[\"Flow (Veh/5 Minutes)\"]]).T)\n",
    "    mergedData = mergedData.append(df,ignore_index=True)\n",
    "    \n",
    "# save the data in one excel \n",
    "#writer = pd.ExcelWriter('./Traffic_Data/merged_data.xlsx')\n",
    "#mergedData.to_excel(writer,index = False)\n",
    "#writer.save()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    " traffic_data = np.vstack(traffic_data)\n",
    "dates = []\n",
    "for date in traffic_data[:, 0]:\n",
    "    traffic_train = []\n",
    "    traffic_test = []\n",
    "    date = date.split()[0]\n",
    "    if date not in dates:\n",
    "        dates.append(date)\n",
    "for data in traffic_data:\n",
    "    curr_day = data[0].split()[0]\n",
    "    if curr_day == dates[-2]: # test on 09/02\n",
    "        traffic_test=np.append(traffic_test,data[1])\n",
    "    else:\n",
    "        traffic_train=np.append(traffic_train,data[1])\n",
    "# make sure data is of type float \n",
    "traffic_train = traffic_train.reshape(traffic_train.shape[0], -1).astype('float32')\n",
    "traffic_test = traffic_test.reshape(traffic_test.shape[0], -1).astype('float32')        \n",
    "\n",
    "def split_xy(data,lookback):\n",
    "    data_x, data_y = [], []\n",
    "    for i in range(len(data)-lookback-1):\n",
    "        data_x.append(data[i:(i+1)])\n",
    "        data_y.append(data[i + 1])\n",
    "    return np.array(data_x), np.array(data_y)  \n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1) \n",
    "random.seed(1)\n",
    "\n",
    "\n",
    "# normalize the dataset\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#traffic_train = scaler.fit_transform(traffic_train)\n",
    "#traffic_test = scaler.fit_transform(traffic_test)\n",
    "\n",
    "# split train and test to x and y \n",
    "train_x, train_y = split_xy(traffic_train,1)\n",
    "test_x, test_y = split_xy(traffic_test,1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
